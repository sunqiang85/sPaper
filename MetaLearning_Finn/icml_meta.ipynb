{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Learning\n",
    "Finn's lecture on ICML 2019: [video](https://www.facebook.com/icml.imls/videos/400619163874853/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems:\n",
    "- no large dataset\n",
    "- want a general-purpose AI System\n",
    "- long tail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:\n",
    "- SIFT features, HOG features\n",
    "- Fine-tuning from ImageNet features\n",
    "- Domain adaption from other painters\n",
    "\n",
    "fewer human priors, more data-driven priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# problem statement\n",
    "two ways to view meta-learning\n",
    "- Mechanistic view\n",
    "    - deep neural network model can read an entire dataset and predictions fro new data points\n",
    "    - Traning this network uwes a meta-dataset, which itself consists of many datases,ch for a different task.\n",
    "- Probalistic view \n",
    "    - Extract prior information from a set of (meta-traing) tasks that allows efficient lerning from new tasks.\n",
    "    - learning a new task uses this prior and (small) traing set to infer most likely posterior parameters\n",
    "    - this view makes it easier to understand meta-learning algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem definitions\n",
    "- supervised learning\n",
    "\n",
    "can we incorporate addtional data?\n",
    "- data from different task: $D_{meta-train}$\n",
    "- data from same task without label: semi-supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The meta-learning problem\n",
    "$$\n",
    "\\arg \\max_{\\Phi} \\log(\\phi | D,D_{meta-train})\n",
    "$$\n",
    "我们不想保存$D_{meta-train}$，我们学习得到$\\theta : p(\\theta| D_{meta-train})$\n",
    "$$\n",
    "\\log p(\\phi | D, D_{meta-train}) = \\log \\int_{\\Theta}p(\\phi | D,\\theta)p(\\theta|D_{meta-train})d\\theta \\\\\n",
    "\\approx \\log p(\\phi|D,\\theta^*) + \\log p(\\theta^*|D_{meta-train})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "后面部分，其实就是meta-learning需要解决的问题\n",
    "$$\n",
    "\\theta^* = \\arg \\max_{\\theta} \\log p(\\theta|D_{meta-train})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面部分，就是特定任务需要解决的问题：\n",
    "$$\n",
    "\\arg \\max \\log p(\\phi|D,D_{meta-train}) = \\arg \\max_{\\phi} \\log p(\\phi|D,\\theta^*)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "key idea:\n",
    "\"our training rocedure is based on a simple machine learning principle: test and train conditons must match\" Vinyals et al., Matching Networks for one-shot learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the complete meta-learning optimization\n",
    "$$\n",
    "\\theta^* = \\max_{\\theta}\\sum_{i=1}^n \\log p(\\phi_i|D_i^{ts})\\\n",
    "$$\n",
    "where $\\phi_i=f_{\\theta}(D_i^{tr})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## meta-learning terminology\n",
    "- meta-training: \n",
    "    - meta-training tasks:\n",
    "        - support set\n",
    "        - query set\n",
    "- meta-test:\n",
    "    - meta-test:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closely related problem settings\n",
    "hyperparameter optimization & auto-ML: can be cast as meta-learning\n",
    "- hyperparameter optimization: $\\theta$ = hyperapameters, $\\phi$= network weights\n",
    "- architecture search: $\\theta$= hyperapameters, $\\phi$= network weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-learning Algorithms\n",
    "- Black-box adaptation\n",
    "- Optimizatin-based inference\n",
    "- Non-Parameter mehtods\n",
    "- Bayesian meta-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to evaluate \n",
    "- 5-way, 1-shot image classification\n",
    "- regreesion, language generation, skill learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how to design a meta-learning algorithm\n",
    "1. Choose a form of $p(\\phi_i|D_i^{tr},\\theta)$\n",
    "2. Choose how to optimeze $\\theta$ w.r.t. max-likeihood objective using $D_{meta-train}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black-box adaptation\n",
    "key idea: train a neural network to represent $p(\\phi_i|D_i^{tr},\\theta)$\n",
    "1. Sample task $T_i$\n",
    "2. Sample disjoint datasets $D_i^{tr}, D_i^{test}$\n",
    "3. Compute $\\phi_i \\leftarrow f_\\theta(D_i^{tr})$\n",
    "4. update $\\theta$ using $\\nabla_\\theta \\mathcal{L}(\\phi_i, D_i^{test})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form of $f_{\\theta}$\n",
    "- LSTM\n",
    "- NTM\n",
    "- self-attention\n",
    "- 1D convolutions\n",
    "- feedforward + average\n",
    "\n",
    "Idea: Do not need to output all parameters of neural net, only sufficient statitics. 只输出关键的参数. MANN, SNAIL\n",
    "\n",
    "general form:\n",
    "$$\n",
    "y^{ts} = f_{\\theta}(D_i^{tr},x^{ts})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization based method\n",
    "key idea: $\\theta$ serves as a prior\n",
    "- Fine-tuning: $\\phi \\leftarrow \\theta-\\alpha \\nabla_\\theta \\mathcal{L}(\\theta, D^{tr})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sample task $T_i$\n",
    "2. Sample disjoint datasets $D_i^{tr}, D_i^{test}$\n",
    "3. Compute $\\phi_i \\leftarrow \\theta-\\alpha \\nabla_\\theta \\mathcal{L}(\\theta, D^{tr})$\n",
    "4. update $\\theta$ using $\\nabla_\\theta \\mathcal{L}(\\phi_i, D_i^{test})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAML: Model-agnostic meta-learning\n",
    "- MAML can be viewed as computational graph\n",
    "- Ravi & Larochelle ICLR'17, Replace gradient update with learned network\n",
    "$$\n",
    "\\phi_i = \\theta - f(\\theta,D_i^{tr},\\nabla_\\theta \\mathcal{L})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "other form:\n",
    "- implicit MAML: Gradient-descent with explicit Gaussian prior \n",
    "- Auto-Meta: Progressive neural architecture search + MAML\n",
    "- Second-order meta-optimization,\n",
    "- Automatically learn iner vector learning rate, tune outer learning rate: Meta-SGD, AlphaMAML\n",
    "- Optimize only a subset of the parameters in the inner loop: DEML, CAVIA\n",
    "- Decouple inner learning rate, BN statistics per-step\n",
    "- Introduce context variables for increased expressive power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Parameter Model\n",
    "can we use parametric meta-learners that produce effective non-parametric learner\n",
    "- learn the metric space: Siamese network\n",
    "\n",
    "\n",
    "can we make meta-train & meta-test match?\n",
    "- Matching Networks\n",
    "\n",
    "prototypical Networks\n",
    "\n",
    "Challenge:\n",
    "\n",
    "learn more complex relationships between datapoints:\n",
    "- Relation Net\n",
    "- IMP\n",
    "- GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## mix & match components of computation graph\n",
    "- both condition on data & run gradient descent: CAML 19\n",
    "- gradient descent on relation net embedding: LEO 19\n",
    "- MAML, but initialize last layer as ProtoNet during meta-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bayesian method\n",
    "model $p(\\phi_i|\\theta)$ as Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application\n",
    "- few-shot image recognition\n",
    "- human motion and pose prediction\n",
    "- domain adaption\n",
    "- few-shot segmentation\n",
    "- few-shot image generation\n",
    "- few-shot image-to-image translation\n",
    "- generation of novel viewpoints\n",
    "- generating talking heads from images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-shot Imitation Learning\n",
    "- meta imitation learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to learn from weak supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other application\n",
    "- adapting to new programs\n",
    "- adapting to new language\n",
    "- adapting to new personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
